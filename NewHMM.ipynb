{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from create_train_test_val_maps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_map_revived = open_map('/home/cs231n/data/train')\n",
    "val_map_revived = open_map('/home/cs231n/data/val')\n",
    "test_map_revived = open_map('/home/cs231n/data/test')\n",
    "codes = [45021, 44004, 43004, 45008, 45002, 45007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get global index from (row, col) index\n",
    "def sub2ind(array_shape, row, col):\n",
    "    ind = row*array_shape[1] + col\n",
    "    if row < 0 or row >= array_shape[0]:\n",
    "        ind = -1\n",
    "    if col < 0 or col >= array_shape[1]:\n",
    "        ind = -1\n",
    "    return ind\n",
    "\n",
    "# get (row, col) index from global index\n",
    "def ind2sub(array_shape, ind):\n",
    "    row = int(ind) / array_shape[1]\n",
    "    col = ind % array_shape[1]\n",
    "    if ind < 0:\n",
    "        row = -1\n",
    "        col = -1\n",
    "    if ind >=  array_shape[0]*array_shape[1]:\n",
    "        row = -1\n",
    "        col = -1\n",
    "    return (row, col)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute softmax function for input. \n",
    "    Use tricks from previous assignment to avoid overflow\n",
    "    \"\"\"\n",
    "\t### YOUR CODE HERE\n",
    "    xshift = np.max(x, axis = 1)\n",
    "    xshift = xshift.reshape((x.shape[0],1))\n",
    "    x = x - xshift\n",
    "    s = np.exp(x) / np.sum(np.exp(x),axis = 1).reshape((x.shape[0],1))\n",
    "\t### END YOUR CODE\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorical Data to Numeric Format\n",
    "\n",
    "# Train Data\n",
    "category_var = ['Veh Ref ID','Event Type Description','Brake Switch','Clutch Switch','Cruise Status','Dpf Regen Inhibit Sw', \n",
    "                'Dpf Thermal Mngmnt','Eng Coolant Level','DTCID']\n",
    "for ATA6code in codes:\n",
    "    for i in range(len(train_map_revived[ATA6code])):\n",
    "        for j in range(len(train_map_revived[ATA6code][i])):\n",
    "            for k in category_var:\n",
    "                train_map_revived[ATA6code][i][j][k] = train_map_revived[ATA6code][i][j][k].astype('category')\n",
    "                train_map_revived[ATA6code][i][j][k] = train_map_revived[ATA6code][i][j][k].cat.codes\n",
    "\n",
    "# Validate Data\n",
    "for ATA6code in codes:\n",
    "    for i in range(len(val_map_revived[ATA6code])):\n",
    "        for j in range(len(val_map_revived[ATA6code][i])):\n",
    "            for k in category_var:\n",
    "                val_map_revived[ATA6code][i][j][k] = val_map_revived[ATA6code][i][j][k].astype('category')\n",
    "                val_map_revived[ATA6code][i][j][k] = val_map_revived[ATA6code][i][j][k].cat.codes\n",
    "                \n",
    "                \n",
    "# Test Data\n",
    "for ATA6code in codes:\n",
    "    for i in range(len(test_map_revived[ATA6code])):\n",
    "        for j in range(len(test_map_revived[ATA6code][i])):\n",
    "            for k in category_var:\n",
    "                test_map_revived[ATA6code][i][j][k] = test_map_revived[ATA6code][i][j][k].astype('category')\n",
    "                test_map_revived[ATA6code][i][j][k] = test_map_revived[ATA6code][i][j][k].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "num_states = 2\n",
    "num_codes = len(codes)\n",
    "num_time_steps = 10\n",
    "num_iter = 10\n",
    "models = []\n",
    "lengths = []\n",
    "\n",
    "# For each code type\n",
    "for i, ATA6code in enumerate(codes):\n",
    "    # For each numer time steps  left\n",
    "    for j in train_map_revived[ATA6code].keys():\n",
    "        #print(j,'\\n')\n",
    "        X = pandas.concat(train_map_revived[ATA6code][j]).as_matrix()[:,2:] # ignore first two columns (veh id, timestamp)\n",
    "        lengths = []\n",
    "        # Concatenate all sequences of that code and time\n",
    "        for sequence_of_snapshots in train_map_revived[ATA6code][j]:\n",
    "            lengths.append(sequence_of_snapshots.shape[0])                \n",
    "        # Make an HMM instance and execute fit (i.e. train)\n",
    "        models.append(hmm.GaussianHMM(n_components=num_states, n_iter=num_iter).fit(X,lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# VALIDATE\n",
    "# Get number of validation samples (sequences)\n",
    "lengths = []\n",
    "for i, ATA6code in enumerate(codes):\n",
    "    for j in val_map_revived[ATA6code].keys():\n",
    "        lengths.append(len(val_map_revived[ATA6code][j]))\n",
    "num_val = np.sum(lengths)\n",
    "\n",
    "\n",
    "# Compute Log Likelihoods for each\n",
    "labels = []\n",
    "s = 0\n",
    "log_likelihoods = np.zeros((num_val, num_codes, num_time_steps))\n",
    "for true_ATA6code in codes:\n",
    "    # time steps \n",
    "    for true_k in val_map_revived[ATA6code].keys():\n",
    "        # for sequence of snapshots\n",
    "        for j,sample in enumerate(val_map_revived[true_ATA6code][true_k]):\n",
    "            # get true labels\n",
    "            labels.append([true_ATA6code,true_k])\n",
    "            for i, ATA6code in enumerate(codes):\n",
    "                for k in val_map_revived[ATA6code].keys():\n",
    "                    x = sample.as_matrix()[:,2:] \n",
    "                    log_likelihoods[s,i,k] = models[sub2ind([num_codes, num_time_steps],i,k)].score(x)\n",
    "            s = s+1\n",
    "labels = np.array(labels).reshape((num_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#accuracy\n",
    "probabilities = np.zeros(log_likelihoods.shape)\n",
    "for s in range(0,num_val):\n",
    "    probabilities_temp = softmax(log_likelihoods[s,:,:].reshape(1,num_codes*num_time_steps))\n",
    "    probabilities[s] = probabilities_temp.reshape(num_codes, num_time_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 6, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.index(labels[1,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
