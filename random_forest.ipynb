{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "\n",
    "# Ignore all GPUs, tf random forest does not benefit from it.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from create_train_test_val_maps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_codes = [0, 45021, 44004, 43004, 45008, 45002, 45007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get global index from (row, col) index\n",
    "def sub2ind(array_shape, row, col):\n",
    "    ind = row*array_shape[1] + col\n",
    "    if row < 0 or row >= array_shape[0]:\n",
    "        ind = -1\n",
    "    if col < 0 or col >= array_shape[1]:\n",
    "        ind = -1\n",
    "    return ind\n",
    "\n",
    "# get (row, col) index from global index\n",
    "def ind2sub(array_shape, ind):\n",
    "    row = int(ind) / array_shape[1]\n",
    "    col = ind % array_shape[1]\n",
    "    if ind < 0:\n",
    "        row = -1\n",
    "        col = -1\n",
    "    if ind >=  array_shape[0]*array_shape[1]:\n",
    "        row = -1\n",
    "        col = -1\n",
    "    return (row, col)\n",
    "\n",
    "def one_hot_labels(labels, num_classes):\n",
    "    one_hot_labels = np.zeros((labels.size, num_classes))\n",
    "    one_hot_labels[np.arange(labels.size),labels.astype(int)] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "def get_data(selected_codes, data_map, num_windows, window_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for vehicleID in data_map.keys():\n",
    "        for ATA6code in data_map[vehicleID].keys():\n",
    "            if ATA6code not in selected_codes:\n",
    "                continue\n",
    "            for window in data_map[vehicleID][ATA6code].keys():\n",
    "                for sequence in data_map[vehicleID][ATA6code][window]:\n",
    "                    Y.extend(list(np.ones((window_size))*sub2ind((len(selected_codes),num_windows),selected_codes.index(ATA6code), window)))\n",
    "                    X.extend(sequence.as_matrix())\n",
    "    X = np.array(X).astype(float)\n",
    "    Y = np.array(Y).astype(int)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "num_classes = 70\n",
    "num_features = 61\n",
    "num_trees = 70\n",
    "max_nodes = 10000\n",
    "\n",
    "data_sizes = [(10, 10)]#, (5,20), (5,50)]\n",
    "trees = [10, 50, 70, 100, 200]\n",
    "\n",
    "train_acc_all = {}\n",
    "val_acc_all = {}\n",
    "train_loss_all = {}\n",
    "\n",
    "for num_windows, window_size in data_sizes:\n",
    "    train_combined, val_combined, test_combined = load_maps(num_windows, window_size)\n",
    "\n",
    "    train_acc_all[(num_windows,window_size)] = {}\n",
    "    val_acc_all[(num_windows,window_size)] = {}\n",
    "    train_loss_all[(num_windows,window_size)] = {}\n",
    "    \n",
    "    train_acc_trees = train_acc_all[(num_windows,window_size)]\n",
    "    train_loss_trees = train_loss_all[(num_windows,window_size)]\n",
    "    val_acc_trees = val_acc_all[(num_windows,window_size)]\n",
    "    \n",
    "    X_train, labels_train = get_data(selected_codes, train_combined, num_windows, window_size)\n",
    "    X_val, labels_val = get_data(selected_codes, val_combined, num_windows, window_size)\n",
    "    X_test, labels_test = get_data(selected_codes, test_combined, num_windows, window_size)\n",
    "    \n",
    "    num_iters = max(X_train.shape[0]//batch_size,1)\n",
    "    \n",
    "    for num_trees in trees:\n",
    "        print(\"Training tree {} with num {} and size {}\".format(num_trees, num_windows, window_size))\n",
    "\n",
    "        train_acc_trees[num_trees] = []\n",
    "        train_loss_trees[num_trees] = []\n",
    "\n",
    "        train_acc = train_acc_trees[num_trees]\n",
    "        train_loss = train_loss_trees[num_trees]\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        # Input and Target data\n",
    "        X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "        # For random forest, labels must be integers (the class id)\n",
    "        Y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "        # Random Forest Parameters\n",
    "        hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                              num_features=num_features,\n",
    "                                              num_trees=num_trees,\n",
    "                                              max_nodes=max_nodes).fill()\n",
    "\n",
    "        # Build the Random Forest\n",
    "        forest_graph = tensor_forest.RandomForestGraphs(hparams)\n",
    "        # Get training graph and loss\n",
    "        train_op = forest_graph.training_graph(X, Y)\n",
    "        loss_op = forest_graph.training_loss(X, Y)\n",
    "\n",
    "        # Measure the accuracy\n",
    "        infer_op = forest_graph.inference_graph(X)\n",
    "        correct_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y, tf.int64))\n",
    "        accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        init_vars = tf.global_variables_initializer()\n",
    "\n",
    "        # Start TensorFlow session\n",
    "        sess = tf.Session()\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init_vars)\n",
    "\n",
    "        # Training\n",
    "        for e in range(num_epochs):\n",
    "            for i in range(num_iters):\n",
    "                start = i*batch_size\n",
    "                end = (i+1)*batch_size\n",
    "                batch_x = X_train[start:end]\n",
    "                batch_y = labels_train[start:end]\n",
    "                _, l = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "                if i % 100 == 0:\n",
    "                    acc = sess.run(accuracy_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "                    train_acc.append([i,acc])\n",
    "                    train_loss.append([i,l])\n",
    "                    #print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))\n",
    "\n",
    "        val_acc_trees[num_trees] = sess.run(accuracy_op, feed_dict={X: X_val, Y: labels_val})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
